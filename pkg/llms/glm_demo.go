package llms

import (
	"context"
	"fmt"
	"log"
	"time"
)

func GLMDemo() {
	fmt.Println("ğŸš€ GLM-4.5 æ¨¡å‹æ¼”ç¤º")
	fmt.Println("==================")

	// 1. åˆ›å»ºGLMå®¢æˆ·ç«¯
	client, err := NewGLMClientFromEnv()
	if err != nil {
		log.Fatal("åˆ›å»ºGLMå®¢æˆ·ç«¯å¤±è´¥:", err)
	}

	// 2. è½¬æ¢ä¸ºGLMå®¢æˆ·ç«¯ä»¥ä½¿ç”¨ç‰¹æ®ŠåŠŸèƒ½
	glmClient, ok := client.(*GLMClient)
	if !ok {
		log.Fatal("å®¢æˆ·ç«¯ç±»å‹è½¬æ¢å¤±è´¥")
	}

	// 3. å±•ç¤ºæ”¯æŒçš„æ¨¡å‹
	fmt.Println("\nğŸ“‹ æ”¯æŒçš„æ¨¡å‹:")
	models := glmClient.GetSupportedModels()
	for i, model := range models {
		fmt.Printf("  %d. %s", i+1, model)
		switch model {
		case "glm-4.5":
			fmt.Print(" (æœ€å¼ºå¤§çš„æ¨ç†æ¨¡å‹ï¼Œ3550äº¿å‚æ•°)")
		case "glm-4.5-air":
			fmt.Print(" (é«˜æ€§ä»·æ¯”è½»é‡çº§å¼ºæ€§èƒ½)")
		case "glm-4.5-x":
			fmt.Print(" (é«˜æ€§èƒ½å¼ºæ¨ç†æé€Ÿå“åº”)")
		case "glm-4.5-airx":
			fmt.Print(" (è½»é‡çº§å¼ºæ€§èƒ½æé€Ÿå“åº”)")
		case "glm-4.5-flash":
			fmt.Print(" (å…è´¹é«˜æ•ˆå¤šåŠŸèƒ½)")
		}
		fmt.Println()
	}

	// 4. åŸºæœ¬èŠå¤©åŠŸèƒ½æ¼”ç¤º
	fmt.Println("\nğŸ’¬ åŸºæœ¬èŠå¤©åŠŸèƒ½æ¼”ç¤º:")
	demonstrateBasicChat(glmClient)

	// 5. æ€è€ƒæ¨¡å¼æ¼”ç¤º
	fmt.Println("\nğŸ¤” æ€è€ƒæ¨¡å¼æ¼”ç¤º:")
	demonstrateThinkingMode(glmClient)

	// 6. ä¸åŒæ¨¡å‹å¯¹æ¯”æ¼”ç¤º
	fmt.Println("\nğŸ”„ ä¸åŒæ¨¡å‹å¯¹æ¯”æ¼”ç¤º:")
	demonstrateModelComparison(glmClient)

	// 7. ä»£ç ç”Ÿæˆæ¼”ç¤º
	fmt.Println("\nğŸ’» ä»£ç ç”Ÿæˆæ¼”ç¤º:")
	demonstrateCodeGeneration(glmClient)

	fmt.Println("\nâœ… GLMæ¼”ç¤ºå®Œæˆï¼")
}

// demonstrateBasicChat æ¼”ç¤ºåŸºæœ¬èŠå¤©åŠŸèƒ½
func demonstrateBasicChat(client *GLMClient) {
	req := &ChatRequest{
		Messages: []Message{
			{Role: "user", Content: "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹GLM-4.5æ¨¡å‹çš„ç‰¹ç‚¹å’Œä¼˜åŠ¿ã€‚"},
		},
		MaxTokens:   800,
		Temperature: 0.7,
	}

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	resp, err := client.Chat(ctx, req)
	if err != nil {
		fmt.Printf("âŒ èŠå¤©è°ƒç”¨å¤±è´¥: %v\n", err)
		return
	}

	if resp.Error != "" {
		fmt.Printf("âŒ APIè¿”å›é”™è¯¯: %s\n", resp.Error)
		return
	}

	fmt.Printf("ğŸ“ å›å¤: %s\n", resp.Content)
	if resp.Usage != nil {
		fmt.Printf("ğŸ“Š Tokenä½¿ç”¨: è¾“å…¥=%d, è¾“å‡º=%d, æ€»è®¡=%d\n",
			resp.Usage.PromptTokens, resp.Usage.CompletionTokens, resp.Usage.TotalTokens)
	}
}

// demonstrateThinkingMode æ¼”ç¤ºæ€è€ƒæ¨¡å¼
func demonstrateThinkingMode(client *GLMClient) {
	req := &ChatRequest{
		Messages: []Message{
			{Role: "user", Content: "è¯·åˆ†æä¸€ä¸‹Goè¯­è¨€å’ŒPythonè¯­è¨€åœ¨å¹¶å‘å¤„ç†æ–¹é¢çš„åŒºåˆ«ï¼Œå¹¶ç»™å‡ºä½¿ç”¨å»ºè®®ã€‚"},
		},
		MaxTokens:   1000,
		Temperature: 0.7,
	}

	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	// ä½¿ç”¨æ€è€ƒæ¨¡å¼
	resp, err := client.ChatWithThinking(ctx, req, true)
	if err != nil {
		fmt.Printf("âŒ æ€è€ƒæ¨¡å¼è°ƒç”¨å¤±è´¥: %v\n", err)
		return
	}

	if resp.Error != "" {
		fmt.Printf("âŒ æ€è€ƒæ¨¡å¼APIè¿”å›é”™è¯¯: %s\n", resp.Error)
		return
	}

	fmt.Printf("ğŸ§  æ€è€ƒæ¨¡å¼å›å¤: %s\n", resp.Content)
	if resp.Usage != nil {
		fmt.Printf("ğŸ“Š æ€è€ƒæ¨¡å¼Tokenä½¿ç”¨: è¾“å…¥=%d, è¾“å‡º=%d, æ€»è®¡=%d\n",
			resp.Usage.PromptTokens, resp.Usage.CompletionTokens, resp.Usage.TotalTokens)
	}
}

// demonstrateModelComparison æ¼”ç¤ºä¸åŒæ¨¡å‹å¯¹æ¯”
func demonstrateModelComparison(client *GLMClient) {
	models := []string{"glm-4.5", "glm-4.5-air", "glm-4.5-flash"}

	for _, model := range models {
		fmt.Printf("\nğŸ” æµ‹è¯•æ¨¡å‹: %s\n", model)
		client.SetModel(model)

		req := &ChatRequest{
			Messages: []Message{
				{Role: "user", Content: "è¯·ç”¨ä¸€å¥è¯ä»‹ç»Goè¯­è¨€çš„ç‰¹ç‚¹ã€‚"},
			},
			MaxTokens:   100,
			Temperature: 0.7,
		}

		ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
		defer cancel()

		resp, err := client.Chat(ctx, req)
		if err != nil {
			fmt.Printf("âŒ æ¨¡å‹ %s è°ƒç”¨å¤±è´¥: %v\n", model, err)
			continue
		}

		if resp.Error != "" {
			fmt.Printf("âŒ æ¨¡å‹ %s APIè¿”å›é”™è¯¯: %s\n", model, resp.Error)
			continue
		}

		if resp.Content == "" {
			fmt.Printf("âš ï¸ æ¨¡å‹ %s è¿”å›å†…å®¹ä¸ºç©º\n", model)
			continue
		}

		fmt.Printf("âœ… æ¨¡å‹ %s å›å¤: %s\n", model, resp.Content)
		if resp.Usage != nil {
			fmt.Printf("ğŸ“Š Tokenä½¿ç”¨: %d\n", resp.Usage.TotalTokens)
		}
	}
}

// demonstrateCodeGeneration æ¼”ç¤ºä»£ç ç”Ÿæˆ
func demonstrateCodeGeneration(client *GLMClient) {
	req := &ChatRequest{
		Messages: []Message{
			{Role: "system", Content: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Goè¯­è¨€å¼€å‘åŠ©æ‰‹ï¼Œæ“…é•¿function-goæ¡†æ¶å¼€å‘ã€‚"},
			{Role: "user", Content: "è¯·å¸®æˆ‘åˆ›å»ºä¸€ä¸ªç®€å•çš„å­¦ç”Ÿä¿¡æ¯ç®¡ç†ç³»ç»Ÿçš„æ•°æ®æ¨¡å‹ï¼Œä½¿ç”¨function-goæ¡†æ¶çš„è§„èŒƒã€‚"},
		},
		MaxTokens:   2000,
		Temperature: 0.7,
	}

	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	resp, err := client.Chat(ctx, req)
	if err != nil {
		fmt.Printf("âŒ ä»£ç ç”Ÿæˆè°ƒç”¨å¤±è´¥: %v\n", err)
		return
	}

	if resp.Error != "" {
		fmt.Printf("âŒ ä»£ç ç”ŸæˆAPIè¿”å›é”™è¯¯: %s\n", resp.Error)
		return
	}

	fmt.Printf("ğŸ’» ç”Ÿæˆçš„ä»£ç :\n%s\n", resp.Content)
	if resp.Usage != nil {
		fmt.Printf("ğŸ“Š Tokenä½¿ç”¨: è¾“å…¥=%d, è¾“å‡º=%d, æ€»è®¡=%d\n",
			resp.Usage.PromptTokens, resp.Usage.CompletionTokens, resp.Usage.TotalTokens)
	}
}
