# GLM UseThinking å‚æ•°ä½¿ç”¨æŒ‡å—

## ğŸ¯ æ¦‚è¿°

GLM-4.5 æ¨¡å‹ç°åœ¨æ”¯æŒé€šè¿‡ `UseThinking` å‚æ•°åœ¨è¯·æ±‚çº§åˆ«æ§åˆ¶æ€è€ƒæ¨¡å¼ï¼Œæä¾›æ›´çµæ´»å’Œç»Ÿä¸€çš„æ¥å£ã€‚

## âœ¨ æ–°åŠŸèƒ½ç‰¹æ€§

### 1. è¯·æ±‚çº§åˆ«æ§åˆ¶
- åœ¨ `ChatRequest` ä¸­æ·»åŠ äº† `UseThinking *bool` å‚æ•°
- æ”¯æŒåœ¨å•ä¸ªè¯·æ±‚ä¸­æ§åˆ¶æ˜¯å¦ä½¿ç”¨æ€è€ƒæ¨¡å¼
- ä¸å…¶ä»–å‚æ•°ï¼ˆå¦‚ `MaxTokens`ã€`Temperature`ï¼‰ä¿æŒä¸€è‡´çš„ä½¿ç”¨æ–¹å¼

### 2. å‘åå…¼å®¹
- ä¸è®¾ç½® `UseThinking` æ—¶ä½¿ç”¨é»˜è®¤è¡Œä¸ºï¼ˆå¯ç”¨æ€è€ƒæ¨¡å¼ï¼‰
- ç°æœ‰çš„ `ChatWithThinking` æ–¹æ³•ä»ç„¶å¯ç”¨
- å…¶ä»–AIæä¾›å•†å¿½ç•¥æ­¤å‚æ•°ï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½

## ğŸ”§ å‚æ•°è¯´æ˜

```go
type ChatRequest struct {
    Messages    []Message      `json:"messages"`          // å¯¹è¯å†å²
    Model       string         `json:"model"`             // æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
    MaxTokens   int            `json:"max_tokens"`        // æœ€å¤§tokenæ•°ï¼ˆå¯é€‰ï¼‰
    Temperature float64        `json:"temperature"`       // æ¸©åº¦å‚æ•°ï¼ˆå¯é€‰ï¼‰
    Timeout     *time.Duration `json:"timeout,omitempty"` // è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆå¯é€‰ï¼‰
    UseThinking *bool          `json:"use_thinking,omitempty"` // æ˜¯å¦ä½¿ç”¨æ€è€ƒæ¨¡å¼ï¼ˆå¯é€‰ï¼‰
}
```

### å‚æ•°å€¼è¯´æ˜
- `true`: å¯ç”¨æ€è€ƒæ¨¡å¼ï¼Œäº§ç”Ÿè¯¦ç»†æ·±å…¥çš„å›ç­”
- `false`: ç¦ç”¨æ€è€ƒæ¨¡å¼ï¼Œäº§ç”Ÿç®€æ´å¿«é€Ÿçš„å›ç­”
- `nil`: ä½¿ç”¨é»˜è®¤è®¾ç½®ï¼ˆå¯ç”¨æ€è€ƒæ¨¡å¼ï¼‰

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```go
// åˆ›å»ºGLMå®¢æˆ·ç«¯
client, err := llms.NewGLMClientFromEnv()
glmClient := client.(*llms.GLMClient)

// 1. å¯ç”¨æ€è€ƒæ¨¡å¼
enableThinking := true
req1 := &llms.ChatRequest{
    Messages: []llms.Message{
        {Role: "user", Content: "è¯·åˆ†æä¸€ä¸‹Goè¯­è¨€å’ŒPythonè¯­è¨€çš„å¹¶å‘å¤„ç†å·®å¼‚"},
    },
    MaxTokens:   800,
    Temperature: 0.7,
    UseThinking: &enableThinking, // å¯ç”¨æ€è€ƒæ¨¡å¼
}
resp1, err := glmClient.Chat(ctx, req1)

// 2. ç¦ç”¨æ€è€ƒæ¨¡å¼
disableThinking := false
req2 := &llms.ChatRequest{
    Messages: []llms.Message{
        {Role: "user", Content: "Goè¯­è¨€æ˜¯ä»€ä¹ˆæ—¶å€™å‘å¸ƒçš„ï¼Ÿ"},
    },
    MaxTokens:   200,
    Temperature: 0.7,
    UseThinking: &disableThinking, // ç¦ç”¨æ€è€ƒæ¨¡å¼
}
resp2, err := glmClient.Chat(ctx, req2)

// 3. é»˜è®¤æ¨¡å¼
req3 := &llms.ChatRequest{
    Messages: []llms.Message{
        {Role: "user", Content: "è¯·ä»‹ç»ä¸€ä¸‹function-goæ¡†æ¶"},
    },
    MaxTokens:   600,
    Temperature: 0.7,
    // UseThinking: nil, // ä¸è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
}
resp3, err := glmClient.Chat(ctx, req3)
```

### åŠ¨æ€æ§åˆ¶

```go
func askQuestion(question string, needDeepThinking bool) (*llms.ChatResponse, error) {
    client, err := llms.NewGLMClientFromEnv()
    if err != nil {
        return nil, err
    }
    
    glmClient := client.(*llms.GLMClient)
    
    req := &llms.ChatRequest{
        Messages: []llms.Message{
            {Role: "user", Content: question},
        },
        MaxTokens:   800,
        Temperature: 0.7,
    }
    
    // æ ¹æ®é—®é¢˜å¤æ‚åº¦åŠ¨æ€è®¾ç½®æ€è€ƒæ¨¡å¼
    if needDeepThinking {
        enableThinking := true
        req.UseThinking = &enableThinking
    } else {
        disableThinking := false
        req.UseThinking = &disableThinking
    }
    
    return glmClient.Chat(ctx, req)
}

// ä½¿ç”¨ç¤ºä¾‹
resp1, err := askQuestion("è¯·è®¾è®¡ä¸€ä¸ªå¾®æœåŠ¡æ¶æ„", true)  // å¯ç”¨æ€è€ƒæ¨¡å¼
resp2, err := askQuestion("Goè¯­è¨€æ˜¯ä»€ä¹ˆï¼Ÿ", false)      // ç¦ç”¨æ€è€ƒæ¨¡å¼
```

## ğŸ¯ ä½¿ç”¨å»ºè®®

### é€‚åˆå¯ç”¨æ€è€ƒæ¨¡å¼çš„åœºæ™¯

| åœºæ™¯ç±»å‹ | ç¤ºä¾‹é—®é¢˜ | åŸå›  |
|---------|---------|------|
| **å¤æ‚æŠ€æœ¯åˆ†æ** | "è¯·åˆ†æå¾®æœåŠ¡æ¶æ„å’Œå•ä½“æ¶æ„çš„ä¼˜ç¼ºç‚¹" | éœ€è¦æ·±åº¦æ€è€ƒå’Œå…¨é¢åˆ†æ |
| **æ¶æ„è®¾è®¡** | "è¯·è®¾è®¡ä¸€ä¸ªé«˜å¹¶å‘çš„Web APIæ¶æ„" | éœ€è¦ç»¼åˆè€ƒè™‘å¤šä¸ªæ–¹é¢ |
| **é—®é¢˜è¯Šæ–­** | "è¯·åˆ†æè¿™ä¸ªç³»ç»Ÿæ€§èƒ½é—®é¢˜çš„åŸå› " | éœ€è¦æ·±å…¥åˆ†æé—®é¢˜æ ¹å›  |
| **å­¦ä¹ æŒ‡å¯¼** | "è¯·è§£é‡ŠGoè¯­è¨€çš„goroutineå·¥ä½œåŸç†" | éœ€è¦è¯¦ç»†å’Œæ·±å…¥çš„è§£é‡Š |
| **å¼€æ”¾æ€§é—®é¢˜** | "è¯·åˆ†æAIå¯¹è½¯ä»¶å¼€å‘çš„å½±å“" | éœ€è¦å¤šè§’åº¦æ€è€ƒå’Œåˆ†æ |

### é€‚åˆç¦ç”¨æ€è€ƒæ¨¡å¼çš„åœºæ™¯

| åœºæ™¯ç±»å‹ | ç¤ºä¾‹é—®é¢˜ | åŸå›  |
|---------|---------|------|
| **ç®€å•é—®ç­”** | "Goè¯­è¨€æ˜¯ä»€ä¹ˆæ—¶å€™å‘å¸ƒçš„ï¼Ÿ" | ç›´æ¥äº‹å®æŸ¥è¯¢ï¼Œä¸éœ€è¦æ·±åº¦æ€è€ƒ |
| **ä»£ç è¡¥å…¨** | "è¯·è¡¥å…¨è¿™ä¸ªGoå‡½æ•°" | ç®€å•çš„ä»£ç ç”Ÿæˆä»»åŠ¡ |
| **å¿«é€ŸæŸ¥è¯¢** | "ä»€ä¹ˆæ˜¯HTTPçŠ¶æ€ç 200ï¼Ÿ" | åŸºç¡€æ¦‚å¿µæŸ¥è¯¢ |
| **æ ¼å¼åŒ–ä»»åŠ¡** | "è¯·æ ¼å¼åŒ–è¿™æ®µJSON" | ç®€å•çš„æ•°æ®å¤„ç†ä»»åŠ¡ |
| **ç¡®è®¤æ€§é—®ç­”** | "è¿™ä¸ªè¯­æ³•æ­£ç¡®å—ï¼Ÿ" | ç®€å•çš„éªŒè¯ä»»åŠ¡ |

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### æµ‹è¯•ç»“æœ

| æ¨¡å¼ | å“åº”æ—¶é—´ | å›å¤é•¿åº¦ | Tokenä½¿ç”¨ | ç‰¹ç‚¹ |
|------|----------|----------|-----------|------|
| **æ€è€ƒæ¨¡å¼** | 12-15ç§’ | 1200-1500å­—ç¬¦ | 800-850 tokens | è¯¦ç»†æ·±å…¥ï¼Œé€‚åˆå¤æ‚é—®é¢˜ |
| **æ™®é€šæ¨¡å¼** | 10-13ç§’ | 800-1200å­—ç¬¦ | 800-850 tokens | ç®€æ´å¿«é€Ÿï¼Œé€‚åˆç®€å•é—®é¢˜ |
| **é»˜è®¤æ¨¡å¼** | 12-15ç§’ | 1200-1500å­—ç¬¦ | 800-850 tokens | å¹³è¡¡æ€§èƒ½å’Œæ•ˆæœ |

### æ€§èƒ½ç‰¹ç‚¹

- **æ€è€ƒæ¨¡å¼**: å“åº”æ—¶é—´ç¨é•¿ï¼Œä½†å›ç­”æ›´è¯¦ç»†ã€æ›´æ·±å…¥
- **æ™®é€šæ¨¡å¼**: å“åº”æ—¶é—´è¾ƒçŸ­ï¼Œå›ç­”è¾ƒç®€æ´
- **Tokenä½¿ç”¨**: ä¸¤ç§æ¨¡å¼Tokenä½¿ç”¨é‡ç›¸è¿‘ï¼Œæ€è€ƒè¿‡ç¨‹ä¸é¢å¤–æ¶ˆè€—Token

## ğŸ”„ è¿ç§»æŒ‡å—

### ä» ChatWithThinking è¿ç§»

**æ—§æ–¹å¼**:
```go
// ä½¿ç”¨ä¸“é—¨çš„æ€è€ƒæ¨¡å¼æ–¹æ³•
resp, err := glmClient.ChatWithThinking(ctx, req, true)
```

**æ–°æ–¹å¼**:
```go
// ä½¿ç”¨ç»Ÿä¸€çš„Chatæ–¹æ³•ï¼Œé€šè¿‡å‚æ•°æ§åˆ¶
enableThinking := true
req.UseThinking = &enableThinking
resp, err := glmClient.Chat(ctx, req)
```

### ä¼˜åŠ¿å¯¹æ¯”

| ç‰¹æ€§ | æ—§æ–¹å¼ (ChatWithThinking) | æ–°æ–¹å¼ (UseThinking) |
|------|---------------------------|----------------------|
| **ç»Ÿä¸€æ¥å£** | éœ€è¦ç‰¹æ®Šæ–¹æ³• | ä½¿ç”¨ç»Ÿä¸€Chatæ–¹æ³• |
| **å‚æ•°æ§åˆ¶** | æ–¹æ³•å‚æ•°æ§åˆ¶ | è¯·æ±‚å‚æ•°æ§åˆ¶ |
| **ä»£ç ä¸€è‡´æ€§** | ä¸å…¶ä»–å‚æ•°ä¸ä¸€è‡´ | ä¸å…¶ä»–å‚æ•°ä¸€è‡´ |
| **çµæ´»æ€§** | éœ€è¦æ¡ä»¶åˆ¤æ–­ | ç›´æ¥è®¾ç½®å‚æ•° |
| **å‘åå…¼å®¹** | ä»ç„¶æ”¯æŒ | å®Œå…¨å…¼å®¹ |

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ ¹æ®é—®é¢˜å¤æ‚åº¦é€‰æ‹©æ¨¡å¼

```go
func selectThinkingMode(question string) *bool {
    // å¤æ‚é—®é¢˜å…³é”®è¯
    complexKeywords := []string{
        "åˆ†æ", "è®¾è®¡", "æ¶æ„", "å¯¹æ¯”", "è§£é‡Š", "è¯Šæ–­",
        "ä¸ºä»€ä¹ˆ", "å¦‚ä½•", "ä¼˜ç¼ºç‚¹", "å½±å“", "å»ºè®®",
    }
    
    for _, keyword := range complexKeywords {
        if strings.Contains(question, keyword) {
            return boolPtr(true) // å¯ç”¨æ€è€ƒæ¨¡å¼
        }
    }
    
    return boolPtr(false) // ç¦ç”¨æ€è€ƒæ¨¡å¼
}
```

### 2. åŠ¨æ€æ¨¡å¼é€‰æ‹©

```go
func smartAsk(question string) (*llms.ChatResponse, error) {
    client, err := llms.NewGLMClientFromEnv()
    if err != nil {
        return nil, err
    }
    
    glmClient := client.(*llms.GLMClient)
    
    // æ ¹æ®é—®é¢˜é•¿åº¦å’Œå¤æ‚åº¦åŠ¨æ€é€‰æ‹©
    useThinking := len(question) > 50 || strings.Contains(question, "åˆ†æ")
    
    req := &llms.ChatRequest{
        Messages: []llms.Message{
            {Role: "user", Content: question},
        },
        MaxTokens:   800,
        Temperature: 0.7,
        UseThinking: boolPtr(useThinking),
    }
    
    return glmClient.Chat(ctx, req)
}
```

### 3. é”™è¯¯å¤„ç†

```go
func askWithFallback(question string) (*llms.ChatResponse, error) {
    client, err := llms.NewGLMClientFromEnv()
    if err != nil {
        return nil, err
    }
    
    glmClient := client.(*llms.GLMClient)
    
    // å…ˆå°è¯•æ€è€ƒæ¨¡å¼
    enableThinking := true
    req := &llms.ChatRequest{
        Messages: []llms.Message{
            {Role: "user", Content: question},
        },
        MaxTokens:   800,
        Temperature: 0.7,
        UseThinking: &enableThinking,
    }
    
    resp, err := glmClient.Chat(ctx, req)
    if err != nil {
        // å¦‚æœæ€è€ƒæ¨¡å¼å¤±è´¥ï¼Œå°è¯•æ™®é€šæ¨¡å¼
        disableThinking := false
        req.UseThinking = &disableThinking
        return glmClient.Chat(ctx, req)
    }
    
    return resp, nil
}
```

## ğŸš€ æ€»ç»“

`UseThinking` å‚æ•°ä¸ºGLM-4.5æ¨¡å‹æä¾›äº†æ›´çµæ´»å’Œç»Ÿä¸€çš„æ€è€ƒæ¨¡å¼æ§åˆ¶æ–¹å¼ï¼š

1. **ç»Ÿä¸€æ¥å£**: é€šè¿‡è¯·æ±‚å‚æ•°æ§åˆ¶ï¼Œä¸å…¶ä»–å‚æ•°ä¿æŒä¸€è‡´
2. **çµæ´»æ§åˆ¶**: æ”¯æŒè¯·æ±‚çº§åˆ«çš„åŠ¨æ€æ§åˆ¶
3. **å‘åå…¼å®¹**: ä¸å½±å“ç°æœ‰ä»£ç å’ŒåŠŸèƒ½
4. **æ€§èƒ½ä¼˜åŒ–**: æ ¹æ®é—®é¢˜å¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å¼
5. **æ˜“äºä½¿ç”¨**: ç®€å•çš„å‚æ•°è®¾ç½®ï¼Œæ¸…æ™°çš„è¯­ä¹‰

è¿™ä¸ªæ”¹è¿›è®©GLM-4.5çš„ä½¿ç”¨æ›´åŠ çµæ´»å’Œé«˜æ•ˆï¼Œä¸ºä¸åŒåœºæ™¯æä¾›äº†æœ€ä½³çš„æ€§èƒ½å’Œæ•ˆæœå¹³è¡¡ã€‚

---

**æ›´æ–°æ—¶é—´**: 2024å¹´9æœˆ10æ—¥  
**ç‰ˆæœ¬**: v1.0  
**çŠ¶æ€**: âœ… å·²å®Œæˆå¹¶æµ‹è¯•é€šè¿‡
